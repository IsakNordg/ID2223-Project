{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from functions import utils\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from functions import utils\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AhdA5UndBaVILBvJ.cvcBxXmN8mo8HPjR1Ryb7XncvNQ6enGsnTHL3LZIUJJ75mpRD0tTptadPTgx4zRu\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "HOPSWORKS_API_KEY = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "\n",
    "os.environ[\"HOPSWORKS_API_KEY\"] = HOPSWORKS_API_KEY\n",
    "print(HOPSWORKS_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITY = \"dublin\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the bike data from csv-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>station</th>\n",
       "      <th>num_bikes_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-06 15:06:11+00:00</td>\n",
       "      <td>AVONDALE_ROAD</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-06 14:48:56+00:00</td>\n",
       "      <td>AVONDALE_ROAD</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-06 13:49:04+00:00</td>\n",
       "      <td>AVONDALE_ROAD</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-06 12:46:44+00:00</td>\n",
       "      <td>AVONDALE_ROAD</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-06 11:49:15+00:00</td>\n",
       "      <td>AVONDALE_ROAD</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056433</th>\n",
       "      <td>2023-08-05 16:54:54+00:00</td>\n",
       "      <td>YORK_STREET_WEST</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056434</th>\n",
       "      <td>2023-08-05 17:56:37+02:00</td>\n",
       "      <td>YORK_STREET_WEST</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056435</th>\n",
       "      <td>2023-08-05 14:51:22+00:00</td>\n",
       "      <td>YORK_STREET_WEST</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056436</th>\n",
       "      <td>2023-08-05 15:54:31+02:00</td>\n",
       "      <td>YORK_STREET_WEST</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056437</th>\n",
       "      <td>2023-08-05 12:56:53+00:00</td>\n",
       "      <td>YORK_STREET_WEST</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1056438 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datetime           station  num_bikes_available\n",
       "0        2025-01-06 15:06:11+00:00     AVONDALE_ROAD                   19\n",
       "1        2025-01-06 14:48:56+00:00     AVONDALE_ROAD                   18\n",
       "2        2025-01-06 13:49:04+00:00     AVONDALE_ROAD                   18\n",
       "3        2025-01-06 12:46:44+00:00     AVONDALE_ROAD                   18\n",
       "4        2025-01-06 11:49:15+00:00     AVONDALE_ROAD                   11\n",
       "...                            ...               ...                  ...\n",
       "1056433  2023-08-05 16:54:54+00:00  YORK_STREET_WEST                   20\n",
       "1056434  2023-08-05 17:56:37+02:00  YORK_STREET_WEST                   16\n",
       "1056435  2023-08-05 14:51:22+00:00  YORK_STREET_WEST                   19\n",
       "1056436  2023-08-05 15:54:31+02:00  YORK_STREET_WEST                   17\n",
       "1056437  2023-08-05 12:56:53+00:00  YORK_STREET_WEST                   18\n",
       "\n",
       "[1056438 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get directory path and all files in it\n",
    "df_bike = pd.DataFrame()\n",
    "for file in os.listdir(CITY):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df_tmp = pd.read_csv(f\"{CITY}/\" + file,  parse_dates=['datetime'], skipinitialspace=True)\n",
    "        df_tmp['station'] = file.split(\".\")[0]\n",
    "        df_bike = pd.concat([df_bike, df_tmp])\n",
    "\n",
    "df_bike = df_bike.set_index(['datetime', 'station']).reset_index(drop=False)\n",
    "\n",
    "df_bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>station</th>\n",
       "      <th>num_bikes_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-06 15:06:11+00:00</td>\n",
       "      <td>AVONDALE_ROAD</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-06 14:48:56+00:00</td>\n",
       "      <td>AVONDALE_ROAD</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-06 13:49:04+00:00</td>\n",
       "      <td>AVONDALE_ROAD</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-06 12:46:44+00:00</td>\n",
       "      <td>AVONDALE_ROAD</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-06 11:49:15+00:00</td>\n",
       "      <td>AVONDALE_ROAD</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056433</th>\n",
       "      <td>2023-08-05 16:54:54+00:00</td>\n",
       "      <td>YORK_STREET_WEST</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056434</th>\n",
       "      <td>2023-08-05 17:56:37+02:00</td>\n",
       "      <td>YORK_STREET_WEST</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056435</th>\n",
       "      <td>2023-08-05 14:51:22+00:00</td>\n",
       "      <td>YORK_STREET_WEST</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056436</th>\n",
       "      <td>2023-08-05 15:54:31+02:00</td>\n",
       "      <td>YORK_STREET_WEST</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056437</th>\n",
       "      <td>2023-08-05 12:56:53+00:00</td>\n",
       "      <td>YORK_STREET_WEST</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1056438 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datetime           station  num_bikes_available\n",
       "0        2025-01-06 15:06:11+00:00     AVONDALE_ROAD                   19\n",
       "1        2025-01-06 14:48:56+00:00     AVONDALE_ROAD                   18\n",
       "2        2025-01-06 13:49:04+00:00     AVONDALE_ROAD                   18\n",
       "3        2025-01-06 12:46:44+00:00     AVONDALE_ROAD                   18\n",
       "4        2025-01-06 11:49:15+00:00     AVONDALE_ROAD                   11\n",
       "...                            ...               ...                  ...\n",
       "1056433  2023-08-05 16:54:54+00:00  YORK_STREET_WEST                   20\n",
       "1056434  2023-08-05 17:56:37+02:00  YORK_STREET_WEST                   16\n",
       "1056435  2023-08-05 14:51:22+00:00  YORK_STREET_WEST                   19\n",
       "1056436  2023-08-05 15:54:31+02:00  YORK_STREET_WEST                   17\n",
       "1056437  2023-08-05 12:56:53+00:00  YORK_STREET_WEST                   18\n",
       "\n",
       "[1056438 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bike.dropna(inplace=True)\n",
    "df_bike\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the weather data from Open Mateo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to get the earliest date of the bike data so that we can get the weater data from Open Mateo for the same period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2023-08-05 12:56:53 UTC', '2025-01-06 15:06:11 UTC')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest_bike_date_raw = pd.Series.min(df_bike['datetime'])\n",
    "earliest_bike_date = earliest_bike_date_raw.strftime('%Y-%m-%d')\n",
    "earliest_bike_datetime = earliest_bike_date_raw.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "last_bike_date_raw = pd.Series.max(df_bike['datetime'])\n",
    "last_bike_date = last_bike_date_raw.strftime('%Y-%m-%d')\n",
    "last_bike_datetime = last_bike_date_raw.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "\n",
    "earliest_bike_datetime, last_bike_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we get the weather data from Open Mateo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 53.32161331176758°N -6.501922607421875°E\n",
      "Elevation 11.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>daylight_duration</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-05 00:00:00+00:00</td>\n",
       "      <td>12.889501</td>\n",
       "      <td>11.347359</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.202726</td>\n",
       "      <td>55572.929688</td>\n",
       "      <td>26.800001</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-05 01:00:00+00:00</td>\n",
       "      <td>12.589500</td>\n",
       "      <td>10.415937</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.114204</td>\n",
       "      <td>55572.929688</td>\n",
       "      <td>26.800001</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-05 02:00:00+00:00</td>\n",
       "      <td>12.339500</td>\n",
       "      <td>9.593327</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.833395</td>\n",
       "      <td>55572.929688</td>\n",
       "      <td>26.800001</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-05 03:00:00+00:00</td>\n",
       "      <td>12.589500</td>\n",
       "      <td>9.265682</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.420181</td>\n",
       "      <td>55572.929688</td>\n",
       "      <td>26.800001</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-05 04:00:00+00:00</td>\n",
       "      <td>12.839500</td>\n",
       "      <td>9.678358</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.264202</td>\n",
       "      <td>55572.929688</td>\n",
       "      <td>26.800001</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12451</th>\n",
       "      <td>2025-01-04 19:00:00+00:00</td>\n",
       "      <td>2.689500</td>\n",
       "      <td>-0.908888</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.108261</td>\n",
       "      <td>27707.722656</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12452</th>\n",
       "      <td>2025-01-04 20:00:00+00:00</td>\n",
       "      <td>2.639500</td>\n",
       "      <td>-1.459750</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.542662</td>\n",
       "      <td>27707.722656</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12453</th>\n",
       "      <td>2025-01-04 21:00:00+00:00</td>\n",
       "      <td>2.189500</td>\n",
       "      <td>-2.205879</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.07</td>\n",
       "      <td>17.337091</td>\n",
       "      <td>27707.722656</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12454</th>\n",
       "      <td>2025-01-04 22:00:00+00:00</td>\n",
       "      <td>1.689500</td>\n",
       "      <td>-3.011362</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.56</td>\n",
       "      <td>19.083395</td>\n",
       "      <td>27707.722656</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12455</th>\n",
       "      <td>2025-01-04 23:00:00+00:00</td>\n",
       "      <td>1.439500</td>\n",
       "      <td>-3.543139</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.56</td>\n",
       "      <td>20.674158</td>\n",
       "      <td>27707.722656</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12456 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       datetime  temperature_2m  apparent_temperature  rain  \\\n",
       "0     2023-08-05 00:00:00+00:00       12.889501             11.347359   0.5   \n",
       "1     2023-08-05 01:00:00+00:00       12.589500             10.415937   4.7   \n",
       "2     2023-08-05 02:00:00+00:00       12.339500              9.593327   4.4   \n",
       "3     2023-08-05 03:00:00+00:00       12.589500              9.265682   2.9   \n",
       "4     2023-08-05 04:00:00+00:00       12.839500              9.678358   2.6   \n",
       "...                         ...             ...                   ...   ...   \n",
       "12451 2025-01-04 19:00:00+00:00        2.689500             -0.908888   0.5   \n",
       "12452 2025-01-04 20:00:00+00:00        2.639500             -1.459750   0.9   \n",
       "12453 2025-01-04 21:00:00+00:00        2.189500             -2.205879   0.8   \n",
       "12454 2025-01-04 22:00:00+00:00        1.689500             -3.011362   0.4   \n",
       "12455 2025-01-04 23:00:00+00:00        1.439500             -3.543139   0.2   \n",
       "\n",
       "       snowfall  wind_speed_10m  daylight_duration   rain_sum    city  \n",
       "0          0.00       13.202726       55572.929688  26.800001  dublin  \n",
       "1          0.00       17.114204       55572.929688  26.800001  dublin  \n",
       "2          0.00       20.833395       55572.929688  26.800001  dublin  \n",
       "3          0.00       25.420181       55572.929688  26.800001  dublin  \n",
       "4          0.00       25.264202       55572.929688  26.800001  dublin  \n",
       "...         ...             ...                ...        ...     ...  \n",
       "12451      0.00       12.108261       27707.722656   3.700000  dublin  \n",
       "12452      0.00       15.542662       27707.722656   3.700000  dublin  \n",
       "12453      0.07       17.337091       27707.722656   3.700000  dublin  \n",
       "12454      0.56       19.083395       27707.722656   3.700000  dublin  \n",
       "12455      0.56       20.674158       27707.722656   3.700000  dublin  \n",
       "\n",
       "[12456 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = utils.get_historical_weather(CITY, earliest_bike_date, last_bike_date)\n",
    "weather_df = weather_df.rename(columns={'date_x': 'datetime'})\n",
    "weather_df.dropna(inplace=True)\n",
    "\n",
    "# remove col date_y, date_only\n",
    "weather_df = weather_df.drop(columns=['date_y', 'date_only'])\n",
    "\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data validation rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we validate that the number of bikes avaliable is always greater than or equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation passed: All values in 'num_bikes_available' are within the range 0 to 100.\n"
     ]
    }
   ],
   "source": [
    "if 'num_bikes_available' not in df_bike.columns:\n",
    "    raise ValueError(\"The column 'num_bikes_available' does not exist in the dataframe.\")\n",
    "\n",
    "invalid_rows = df_bike[(df_bike['num_bikes_available'] < 0) | (df_bike['num_bikes_available'] > 100)]\n",
    "\n",
    "if not invalid_rows.empty:\n",
    "    print(\"Validation failed: Some rows have invalid values in 'num_bikes_available'.\")\n",
    "    print(invalid_rows)\n",
    "    assert False\n",
    "else:\n",
    "    print(\"Validation passed: All values in 'num_bikes_available' are within the range 0 to 100.\")\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we validate that the rainfall, snowfall, and wind speed are always greater than or equal to zero, and below 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation passed: All values in the specified columns are within the range 0 to 1000.\n"
     ]
    }
   ],
   "source": [
    "if 'rain' not in weather_df.columns:\n",
    "    raise ValueError(\"The column 'rain' does not exist in the dataframe.\")\n",
    "if 'snowfall' not in weather_df.columns:\n",
    "    raise ValueError(\"The column 'snowfall' does not exist in the dataframe.\")\n",
    "if 'wind_speed_10m' not in weather_df.columns:\n",
    "    raise ValueError(\"The column 'wind_speed_10m' does not exist in the dataframe.\")\n",
    "\n",
    "invalid_rows = weather_df[(weather_df['rain'] < 0) | (weather_df['rain'] > 1000) |\n",
    "                          (weather_df['snowfall'] < 0) | (weather_df['snowfall'] > 1000) |\n",
    "                          (weather_df['wind_speed_10m'] < 0) | (weather_df['wind_speed_10m'] > 1000)]\n",
    "\n",
    "if not invalid_rows.empty:\n",
    "    print(\"Validation failed: Some rows have invalid values in the specified columns.\")\n",
    "    print(invalid_rows)\n",
    "    assert False\n",
    "else:\n",
    "    print(\"Validation passed: All values in the specified columns are within the range 0 to 1000.\")\n",
    "    assert True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Hopsworks and create two feature groups (+more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1207494\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-06 17:44:43,349 INFO: Initializing external client\n",
      "2025-01-06 17:44:43,350 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "secrets = utils.secrets_api(project.name)\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the city location and times for the data to Hopsworks for easy access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    }
   ],
   "source": [
    "latitude, longitude = utils.get_city_coordinates(CITY)\n",
    "\n",
    "city_secrets_dict = {\n",
    "    \"city\": CITY,\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude,\n",
    "}\n",
    "\n",
    "time_secrets_dict = {\n",
    "    \"earliest_bike_datetime\": earliest_bike_datetime,\n",
    "    \"last_bike_datetime\": last_bike_datetime\n",
    "}\n",
    "\n",
    "city_secrets_json = json.dumps(city_secrets_dict)\n",
    "time_secrets_json = json.dumps(time_secrets_dict)\n",
    "\n",
    "try:\n",
    "    secrets.create_secret(\"city_secrets\", city_secrets_json)\n",
    "except hopsworks.RestAPIError:\n",
    "    print(\"city_secrets already exists. To update, delete the secret in the UI (https://c.app.hopsworks.ai/account/secrets) and re-run this cell.\")\n",
    "    existing_key = secrets.get_secret(\"city_secrets\").value\n",
    "    print(f\"{existing_key}\")\n",
    "    print()\n",
    "\n",
    "try:\n",
    "    secrets.create_secret(\"time_secrets\", time_secrets_json)\n",
    "except hopsworks.RestAPIError:\n",
    "    print(\"time_secrets already exists. To update, delete the secret in the UI (https://c.app.hopsworks.ai/account/secrets) and re-run this cell.\")\n",
    "    existing_key = secrets.get_secret(\"time_secrets\").value\n",
    "    print(f\"{existing_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature group 1: Bike data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1207494/fs/1195126/fg/1393630\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db9b65e2dd94e49a32ae4a8fac2c374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1056438 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: bike_data_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "http://c.app.hopsworks.ai/p/1207494/jobs/named/bike_data_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x1aac5ff31f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_fg = fs.get_or_create_feature_group(\n",
    "    name='bike_data',\n",
    "    description='How many bikes are available at each station at a given time',\n",
    "    version=1,\n",
    "    primary_key=[\"datetime\", \"station\"],\n",
    "    event_time=\"datetime\"\n",
    ")\n",
    "\n",
    "bike_fg.insert(df_bike)\n",
    "\n",
    "bike_fg.update_feature_description(\"num_bikes_available\", \"Number of bikes available at the station\")\n",
    "bike_fg.update_feature_description(\"datetime\", \"Timestamp of the observation\")\n",
    "bike_fg.update_feature_description(\"station\", \"Name of the station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature group 2: Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-07 07:40:05,834 ERROR: Flight returned unavailable error, with message: failed to connect to all addresses; last error: UNKNOWN: ipv4:3.19.160.248:5005: tcp handshaker shutdown\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 192, in __init__\n",
      "    self._health_check()\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 56, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 266, in call\n",
      "    raise attempt.get()\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 301, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\six.py\", line 724, in reraise\n",
      "    raise value\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 251, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 286, in _health_check\n",
      "    list(self._connection.do_action(action, options=options))\n",
      "  File \"pyarrow\\\\_flight.pyx\", line 1556, in _do_action_response\n",
      "  File \"pyarrow\\\\_flight.pyx\", line 68, in pyarrow._flight.check_flight_status\n",
      "pyarrow._flight.FlightUnavailableError: Flight returned unavailable error, with message: failed to connect to all addresses; last error: UNKNOWN: ipv4:3.19.160.248:5005: tcp handshaker shutdown\n",
      "2025-01-07 07:40:30,028 ERROR: Flight returned unavailable error, with message: failed to connect to all addresses; last error: UNKNOWN: ipv4:3.19.160.248:5005: tcp handshaker shutdown\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 350, in afs_error_handler_wrapper\n",
      "    return func(instance, *args, **kw)\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 411, in read_query\n",
      "    return self._get_dataset(\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 56, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 266, in call\n",
      "    raise attempt.get()\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 301, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\six.py\", line 724, in reraise\n",
      "    raise value\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 251, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 396, in _get_dataset\n",
      "    info = self.get_flight_info(descriptor)\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 56, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 266, in call\n",
      "    raise attempt.get()\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 301, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\six.py\", line 724, in reraise\n",
      "    raise value\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py\", line 251, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"c:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 383, in get_flight_info\n",
      "    return self._connection.get_flight_info(\n",
      "  File \"pyarrow\\\\_flight.pyx\", line 1600, in pyarrow._flight.FlightClient.get_flight_info\n",
      "  File \"pyarrow\\\\_flight.pyx\", line 68, in pyarrow._flight.check_flight_status\n",
      "pyarrow._flight.FlightUnavailableError: Flight returned unavailable error, with message: failed to connect to all addresses; last error: UNKNOWN: ipv4:3.19.160.248:5005: tcp handshaker shutdown\n",
      "Error: Reading data from Hopsworks, using Hopsworks Feature Query Service           \n"
     ]
    },
    {
     "ename": "FeatureStoreException",
     "evalue": "Could not read data using Hopsworks Feature Query Service. If the issue persists, use read_options={\"use_hive\": True} instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFlightUnavailableError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\core\\arrow_flight_client.py:350\u001b[0m, in \u001b[0;36mArrowFlightClient._handle_afs_exception.<locals>.decorator.<locals>.afs_error_handler_wrapper\u001b[1;34m(instance, *args, **kw)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\core\\arrow_flight_client.py:411\u001b[0m, in \u001b[0;36mArrowFlightClient.read_query\u001b[1;34m(self, query_object, arrow_flight_config, dataframe_type)\u001b[0m\n\u001b[0;32m    410\u001b[0m descriptor \u001b[38;5;241m=\u001b[39m pyarrow\u001b[38;5;241m.\u001b[39mflight\u001b[38;5;241m.\u001b[39mFlightDescriptor\u001b[38;5;241m.\u001b[39mfor_command(query_encoded)\n\u001b[1;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescriptor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrow_flight_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrow_flight_config\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py:56\u001b[0m, in \u001b[0;36mretry.<locals>.wrap.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;129m@six\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Retrying(\u001b[38;5;241m*\u001b[39mdargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdkw)\u001b[38;5;241m.\u001b[39mcall(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py:266\u001b[0m, in \u001b[0;36mRetrying.call\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_exception \u001b[38;5;129;01mand\u001b[39;00m attempt\u001b[38;5;241m.\u001b[39mhas_exception:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# get() on an attempt with an exception should cause it to be raised, but raise just in case\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mattempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py:301\u001b[0m, in \u001b[0;36mAttempt.get\u001b[1;34m(self, wrap_exception)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 301\u001b[0m         \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\six.py:724\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py:251\u001b[0m, in \u001b[0;36mRetrying.call\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     attempt \u001b[38;5;241m=\u001b[39m Attempt(fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), attempt_number, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\core\\arrow_flight_client.py:396\u001b[0m, in \u001b[0;36mArrowFlightClient._get_dataset\u001b[1;34m(self, descriptor, timeout, dataframe_type)\u001b[0m\n\u001b[0;32m    395\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\n\u001b[1;32m--> 396\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flight_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescriptor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    397\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieved flight info: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Fetching dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(info))\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py:56\u001b[0m, in \u001b[0;36mretry.<locals>.wrap.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;129m@six\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Retrying(\u001b[38;5;241m*\u001b[39mdargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdkw)\u001b[38;5;241m.\u001b[39mcall(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py:266\u001b[0m, in \u001b[0;36mRetrying.call\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_exception \u001b[38;5;129;01mand\u001b[39;00m attempt\u001b[38;5;241m.\u001b[39mhas_exception:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# get() on an attempt with an exception should cause it to be raised, but raise just in case\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mattempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py:301\u001b[0m, in \u001b[0;36mAttempt.get\u001b[1;34m(self, wrap_exception)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 301\u001b[0m         \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\six.py:724\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\retrying.py:251\u001b[0m, in \u001b[0;36mRetrying.call\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     attempt \u001b[38;5;241m=\u001b[39m Attempt(fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), attempt_number, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\core\\arrow_flight_client.py:383\u001b[0m, in \u001b[0;36mArrowFlightClient.get_flight_info\u001b[1;34m(self, descriptor)\u001b[0m\n\u001b[0;32m    382\u001b[0m options \u001b[38;5;241m=\u001b[39m pyarrow\u001b[38;5;241m.\u001b[39mflight\u001b[38;5;241m.\u001b[39mFlightCallOptions(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhealth_check_timeout)\n\u001b[1;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flight_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescriptor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\pyarrow\\_flight.pyx:1600\u001b[0m, in \u001b[0;36mpyarrow._flight.FlightClient.get_flight_info\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\pyarrow\\_flight.pyx:68\u001b[0m, in \u001b[0;36mpyarrow._flight.check_flight_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFlightUnavailableError\u001b[0m: Flight returned unavailable error, with message: failed to connect to all addresses; last error: UNKNOWN: ipv4:3.19.160.248:5005: tcp handshaker shutdown",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFeatureStoreException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m weather_fg\u001b[38;5;241m.\u001b[39mupdate_feature_description(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdaylight_duration\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDaylight duration in seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m weather_fg\u001b[38;5;241m.\u001b[39mupdate_feature_description(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrain_sum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal rain in mm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mweather_fg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\feature_group.py:2382\u001b[0m, in \u001b[0;36mFeatureGroup.show\u001b[1;34m(self, n, online)\u001b[0m\n\u001b[0;32m   2357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Show the first `n` rows of the feature group.\u001b[39;00m\n\u001b[0;32m   2358\u001b[0m \n\u001b[0;32m   2359\u001b[0m \u001b[38;5;124;03m!!! example\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2374\u001b[0m \u001b[38;5;124;03m        to `False`.\u001b[39;00m\n\u001b[0;32m   2375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2376\u001b[0m engine\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mset_job_group(\n\u001b[0;32m   2377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching Feature group\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting feature group: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m from the featurestore \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_store_name\n\u001b[0;32m   2380\u001b[0m     ),\n\u001b[0;32m   2381\u001b[0m )\n\u001b[1;32m-> 2382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\constructor\\query.py:236\u001b[0m, in \u001b[0;36mQuery.show\u001b[1;34m(self, n, online)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     sql_query, online_conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prep_read(online, read_options)\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_store_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monline_conn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_options\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\engine\\python.py:509\u001b[0m, in \u001b[0;36mEngine.show\u001b[1;34m(self, sql_query, feature_store, n, online_conn, read_options)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    503\u001b[0m     sql_query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m     read_options: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    508\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[pd\u001b[38;5;241m.\u001b[39mDataFrame, pl\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monline_conn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead(n)\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\engine\\python.py:168\u001b[0m, in \u001b[0;36mEngine.sql\u001b[1;34m(self, sql_query, feature_store, online_conn, dataframe_type, read_options, schema)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msql\u001b[39m(\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    160\u001b[0m     sql_query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m     schema: Optional[List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature.Feature\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[pd\u001b[38;5;241m.\u001b[39mDataFrame, pl\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m online_conn:\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sql_offline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataframe_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhive_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhive_config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mread_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43marrow_flight_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marrow_flight_config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mread_options\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdbc(\n\u001b[0;32m    180\u001b[0m             sql_query, online_conn, dataframe_type, read_options, schema\n\u001b[0;32m    181\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\engine\\python.py:212\u001b[0m, in \u001b[0;36mEngine._sql_offline\u001b[1;34m(self, sql_query, feature_store, dataframe_type, schema, hive_config, arrow_flight_config)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dataframe_type(dataframe_type)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql_query, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_string\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sql_query:\n\u001b[1;32m--> 212\u001b[0m     result_df \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_loading_animation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReading data from Hopsworks, using Hopsworks Feature Query Service\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrow_flight_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrow_flight_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_hive_connection(\n\u001b[0;32m    221\u001b[0m         feature_store, hive_config\u001b[38;5;241m=\u001b[39mhive_config\n\u001b[0;32m    222\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m hive_conn:\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;66;03m# Suppress SQLAlchemy pandas warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\util.py:486\u001b[0m, in \u001b[0;36mrun_with_loading_animation\u001b[1;34m(message, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    487\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\isakn\\miniconda3\\envs\\SML_Project\\lib\\site-packages\\hsfs\\core\\arrow_flight_client.py:368\u001b[0m, in \u001b[0;36mArrowFlightClient._handle_afs_exception.<locals>.decorator.<locals>.afs_error_handler_wrapper\u001b[1;34m(instance, *args, **kw)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(user_message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mFeatureStoreException\u001b[0m: Could not read data using Hopsworks Feature Query Service. If the issue persists, use read_options={\"use_hive\": True} instead."
     ]
    }
   ],
   "source": [
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name='weather_data',\n",
    "    description='Weather data for the city',\n",
    "    version=1,\n",
    "    primary_key=[\"datetime\"],\n",
    "    event_time=\"datetime\"\n",
    ")\n",
    "\n",
    "weather_fg.insert(weather_df)\n",
    "\n",
    "# \"hourly\": [\"temperature_2m\", \"apparent_temperature\", \"rain\", \"snowfall\", \"snow_depth\", \"wind_speed_10m\"],\n",
    "# \"daily\": [\"sunshine_duration\", \"daylight_duration\", \"rain_sum\"]\n",
    "\n",
    "weather_fg.update_feature_description(\"datetime\", \"Timestamp of the observation\")\n",
    "weather_fg.update_feature_description(\"temperature_2m\", \"Temperature in Celsius\")\n",
    "weather_fg.update_feature_description(\"apparent_temperature\", \"Apparent temperature in Celsius\")\n",
    "weather_fg.update_feature_description(\"rain\", \"Rain percipitation in mm\")\n",
    "weather_fg.update_feature_description(\"snowfall\", \"Snowfall in mm\")\n",
    "weather_fg.update_feature_description(\"wind_speed_10m\", \"Wind speed 10 m above ground level\")\n",
    "weather_fg.update_feature_description(\"daylight_duration\", \"Daylight duration in seconds\")\n",
    "weather_fg.update_feature_description(\"rain_sum\", \"Total rain in mm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SML_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
