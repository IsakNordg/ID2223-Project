{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from functions import utils\n",
    "import json\n",
    "import os\n",
    "import git\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "HOPSWORKS_API_KEY = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "os.environ[\"HOPSWORKS_API_KEY\"] = HOPSWORKS_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the necessary data from Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 17:05:58,501 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-01-08 17:05:58,564 INFO: Initializing external client\n",
      "2025-01-08 17:05:58,566 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-08 17:05:59,936 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1207494\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() \n",
    "# secrets = utils.secrets_api(project.name)\n",
    "\n",
    "CITY = \"dublin\"\n",
    "STATION = \"HEUSTON BRIDGE (NORTH)\"\n",
    "\n",
    "# latitude =\n",
    "# longitude =\n",
    "\n",
    "today = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "bike_fg = fs.get_feature_group(\n",
    "    name='bike_data',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather_data',\n",
    "    version=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone and pull the repository with the bike data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "REPO_URL = \"https://github.com/MaxHalford/bike-sharing-history\"\n",
    "CLONE_DIR = \"./bike_data/bike-sharing-history\"\n",
    "TARGET_CITY = \"dublin\"\n",
    "FILE_NAME = \"jcdecaux.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<git.remote.FetchInfo at 0x1d20eb61fd0>,\n",
       " <git.remote.FetchInfo at 0x1d20e7b8d60>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(CLONE_DIR):\n",
    "    print(\"Cloning repository...\")\n",
    "    git.Repo.clone_from(REPO_URL, CLONE_DIR)\n",
    "repo = git.Repo(CLONE_DIR)\n",
    "\n",
    "# go to main and pull the latest changes\n",
    "repo.git.checkout(\"main\", force=True)\n",
    "repo.remotes.origin.pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the latest datetime present in the bike data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.47s) \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2025-01-08 15:00:00 UTC'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last_bike_datetime = \"2025-01-06 15:06:11 UTC\"\n",
    "\n",
    "bike_df = bike_fg.read()\n",
    "\n",
    "last_bike_datetime = bike_df[\"datetime\"].max()\n",
    "last_bike_datetime = last_bike_datetime.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "\n",
    "last_bike_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through the commits and convert the bike data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# Populate the results dict with the stations\n",
    "data_file = os.path.join(CLONE_DIR, \"data/stations/\" + TARGET_CITY + \"/\" + FILE_NAME)\n",
    "if os.path.exists(data_file):\n",
    "    with open(data_file, \"r\") as f:\n",
    "        data = f.read()\n",
    "        data = json.loads(data)\n",
    "        for feature in data[\"features\"]:\n",
    "            name = feature[\"properties\"][\"name\"]\n",
    "            results[name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breaking at:  2025-01-08 14:49:05+00:00\n",
      "{'CLARENDON ROW': [], 'BLESSINGTON STREET': [], 'BOLTON STREET': [], 'GREEK STREET': [], 'CHARLEMONT PLACE': [], 'CHRISTCHURCH PLACE': [], 'HIGH STREET': [], 'CUSTOM HOUSE QUAY': [], 'EXCHEQUER STREET': [], 'DAME STREET': [], 'EARLSFORT TERRACE': [], 'ECCLES STREET': [], 'FITZWILLIAM SQUARE WEST': [], 'FOWNES STREET UPPER': [], 'HARDWICKE STREET': [], 'GEORGES QUAY': [], 'GOLDEN LANE': [], 'GRANTHAM STREET': [], 'HERBERT PLACE': [], 'JAMES STREET EAST': [], 'LEINSTER STREET SOUTH': [], 'TOWNSEND STREET': [], 'CUSTOM HOUSE': [], 'CATHAL BRUGHA STREET': [], 'MERRION SQUARE EAST': [], 'MERRION SQUARE WEST': [], 'MOLESWORTH STREET': [], 'MOUNTJOY SQUARE WEST': [], 'ORMOND QUAY UPPER': [], 'PARNELL SQUARE NORTH': [], 'PARNELL STREET': [], 'PEARSE STREET': [], \"PRINCES STREET / O'CONNELL STREET\": [], 'PORTOBELLO HARBOUR': [], 'SMITHFIELD': [], \"ST. STEPHEN'S GREEN EAST\": [], \"ST. STEPHEN'S GREEN SOUTH\": [], 'TALBOT STREET': [], 'WILTON TERRACE': [], 'JERVIS STREET': [], 'HARCOURT TERRACE': [], 'SMITHFIELD NORTH': [], 'PORTOBELLO ROAD': [], 'UPPER SHERRARD STREET': [], 'DEVERELL PLACE': [], 'HERBERT STREET': [], 'EXCISE WALK': [], 'GUILD STREET': [], 'GEORGES LANE': [], 'YORK STREET WEST': [], 'YORK STREET EAST': [], 'NEWMAN HOUSE': [], 'CLONMEL STREET': [], 'HATCH STREET': [], 'MOUNT STREET LOWER': [], 'GRATTAN STREET': [], \"SIR PATRICK DUN'S\": [], 'DENMARK STREET GREAT': [], 'NORTH CIRCULAR ROAD': [], 'HARDWICKE PLACE': [], 'LIME STREET': [], 'FENIAN STREET': [], 'SANDWITH STREET': [], 'CONVENTION CENTRE': [], 'NEW CENTRAL BANK': [], 'THE POINT': [], 'HANOVER QUAY': [], 'GRAND CANAL DOCK': [], 'KEVIN STREET': [], 'JOHN STREET WEST': [], 'FRANCIS STREET': [], 'OLIVER BOND STREET': [], 'JAMES STREET': [], 'MARKET STREET SOUTH': [], 'WOLFE TONE STREET': [], 'MATER HOSPITAL': [], 'ECCLES STREET EAST': [], 'ST JAMES HOSPITAL (LUAS)': [], 'MOUNT BROWN': [], 'EMMET ROAD': [], 'BROOKFIELD ROAD': [], 'ROTHE ABBEY': [], 'PARKGATE STREET': [], 'COLLINS BARRACKS MUSEUM': [], 'BLACKHALL PLACE': [], 'FITZWILLIAM SQUARE EAST': [], 'BENSON STREET': [], 'SOUTH DOCK ROAD': [], 'HEUSTON BRIDGE (NORTH)': [], 'HEUSTON STATION (CENTRAL)': [], 'HEUSTON STATION (CAR PARK)': [], 'ROYAL HOSPITAL': [], 'KILMAINHAM LANE': [], 'KILMAINHAM GAOL': [], 'FREDERICK STREET SOUTH': [], 'CITY QUAY': [], 'HEUSTON BRIDGE (SOUTH)': [], 'KING STREET NORTH': [], 'WESTERN WAY': [], 'GRANGEGORMAN LOWER (SOUTH)': [], 'GRANGEGORMAN LOWER (CENTRAL)': [], 'GRANGEGORMAN LOWER (NORTH)': [], 'RATHDOWN ROAD': [], 'CHARLEVILLE ROAD': [], 'AVONDALE ROAD': [], 'BUCKINGHAM STREET LOWER': [], 'PHIBSBOROUGH ROAD': [], 'MOUNTJOY SQUARE EAST': [], \"NORTH CIRCULAR ROAD (O'CONNELL'S)\": [], 'MERRION SQUARE SOUTH': [], 'WILTON TERRACE (PARK)': [], 'KILLARNEY STREET': [], 'BROADSTONE': [], 'HANOVER QUAY EAST': []}\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "last_day_and_hour = None\n",
    "\n",
    "for commit in repo.iter_commits():\n",
    "    # Stop when we reach the earliest bike date\n",
    "    if commit.committed_datetime <= datetime.datetime.strptime(last_bike_datetime, \"%Y-%m-%d %H:%M:%S %Z\").replace(tzinfo=datetime.timezone.utc):\n",
    "        print(\"breaking at: \", commit.committed_datetime)\n",
    "        break\n",
    "\n",
    "    # Skip commits from today\n",
    "    if commit.committed_datetime > today.replace(tzinfo=datetime.timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0):\n",
    "        first_commited_datetime = repo.commit().committed_datetime\n",
    "        continue\n",
    "\n",
    "    day_and_hour = commit.committed_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    # print(\"day_and_hour: \", day_and_hour, \" - last_day_and_hour: \", last_day_and_hour)\n",
    "    if day_and_hour == last_day_and_hour:\n",
    "        continue\n",
    "    last_day_and_hour = day_and_hour\n",
    "\n",
    "    # Get the data for the commit\n",
    "    print(\"Processing commit: \", commit.hexsha, \" - \", commit.committed_datetime)\n",
    "    try:\n",
    "        repo.git.checkout(commit.hexsha, force=True)\n",
    "    except Exception as e:\n",
    "        print(\"Error checking out commit: \", e)\n",
    "        break\n",
    "\n",
    "    data_file = os.path.join(CLONE_DIR, \"data/stations/\" + TARGET_CITY + \"/\" + FILE_NAME)\n",
    "    if os.path.exists(data_file):\n",
    "        with open(data_file, \"r\") as f:\n",
    "            data = f.read()\n",
    "            data = json.loads(data)\n",
    "            for feature in data[\"features\"]:\n",
    "                try:\n",
    "                    results[feature[\"properties\"][\"name\"]].append([feature[\"properties\"][\"available_bikes\"], commit.committed_datetime])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn results into a dataframe\n",
    "df_bike_today = pd.DataFrame()\n",
    "\n",
    "for station, values in results.items():\n",
    "    if len(values) > 0:\n",
    "        df = pd.DataFrame(values, columns=[\"num_bikes_available\", \"datetime\"])\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], utc=True)\n",
    "        df[\"station\"] = station.replace(\" \", \"_\")\n",
    "        df_bike_today = pd.concat([df_bike_today, df])\n",
    "\n",
    "# if empty, do nothing\n",
    "if not df_bike_today.empty:\n",
    "    df_bike_today.dropna(inplace=True)\n",
    "    df_bike_today[\"num_bikes_available\"] = df_bike_today[\"num_bikes_available\"].astype(\"float32\")\n",
    "    df_bike_today = df_bike_today[df_bike_today['station'].isin([STATION.replace(\" \", \"_\")])]\n",
    "    df_bike_today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the weather data for the same time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: {'hourly': ['temperature_2m', 'apparent_temperature', 'rain', 'snowfall', 'wind_speed_10m'], 'daily': ['daylight_duration', 'rain_sum']}\n",
      "params: {'latitude': 53.35, 'longitude': -6.26, 'hourly': ['temperature_2m', 'apparent_temperature', 'rain', 'snowfall', 'wind_speed_10m'], 'daily': ['daylight_duration', 'rain_sum']}\n",
      "Coordinates 53.5°N -6.25°E\n",
      "Elevation 11.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>daylight_duration</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-08 00:00:00+00:00</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-5.474496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.324414</td>\n",
       "      <td>28021.865234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-08 01:00:00+00:00</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-5.587059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.542478</td>\n",
       "      <td>28021.865234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-08 02:00:00+00:00</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>-5.520480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.440001</td>\n",
       "      <td>28021.865234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-08 03:00:00+00:00</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-5.586253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.726665</td>\n",
       "      <td>28021.865234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-08 04:00:00+00:00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-5.771173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.669949</td>\n",
       "      <td>28021.865234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2025-01-17 19:00:00+00:00</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.534287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.578890</td>\n",
       "      <td>29351.843750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2025-01-17 20:00:00+00:00</td>\n",
       "      <td>4.85</td>\n",
       "      <td>1.368568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.277983</td>\n",
       "      <td>29351.843750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2025-01-17 21:00:00+00:00</td>\n",
       "      <td>4.60</td>\n",
       "      <td>1.185653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.479583</td>\n",
       "      <td>29351.843750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2025-01-17 22:00:00+00:00</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.943740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.682018</td>\n",
       "      <td>29351.843750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2025-01-17 23:00:00+00:00</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.744604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.384198</td>\n",
       "      <td>29351.843750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dublin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     datetime  temperature_2m  apparent_temperature  rain  \\\n",
       "0   2025-01-08 00:00:00+00:00           -1.25             -5.474496   0.0   \n",
       "1   2025-01-08 01:00:00+00:00           -1.45             -5.587059   0.0   \n",
       "2   2025-01-08 02:00:00+00:00           -1.55             -5.520480   0.0   \n",
       "3   2025-01-08 03:00:00+00:00           -1.70             -5.586253   0.0   \n",
       "4   2025-01-08 04:00:00+00:00           -2.00             -5.771173   0.0   \n",
       "..                        ...             ...                   ...   ...   \n",
       "235 2025-01-17 19:00:00+00:00            5.05              1.534287   0.0   \n",
       "236 2025-01-17 20:00:00+00:00            4.85              1.368568   0.0   \n",
       "237 2025-01-17 21:00:00+00:00            4.60              1.185653   0.0   \n",
       "238 2025-01-17 22:00:00+00:00            4.30              0.943740   0.0   \n",
       "239 2025-01-17 23:00:00+00:00            3.95              0.744604   0.0   \n",
       "\n",
       "     snowfall  wind_speed_10m  daylight_duration  rain_sum    city  \n",
       "0         0.0       12.324414       28021.865234       0.0  dublin  \n",
       "1         0.0       11.542478       28021.865234       0.0  dublin  \n",
       "2         0.0       10.440001       28021.865234       0.0  dublin  \n",
       "3         0.0        9.726665       28021.865234       0.0  dublin  \n",
       "4         0.0        8.669949       28021.865234       0.0  dublin  \n",
       "..        ...             ...                ...       ...     ...  \n",
       "235       0.0       14.578890       29351.843750       0.0  dublin  \n",
       "236       0.0       14.277983       29351.843750       0.0  dublin  \n",
       "237       0.0       13.479583       29351.843750       0.0  dublin  \n",
       "238       0.0       12.682018       29351.843750       0.0  dublin  \n",
       "239       0.0       11.384198       29351.843750       0.0  dublin  \n",
       "\n",
       "[240 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df = utils.get_hourly_weather_forecast(CITY)\n",
    "forecast_df = forecast_df.rename(columns={'date_x': 'datetime'})\n",
    "forecast_df = forecast_df.drop(columns=['date_y', 'date_only'])\n",
    "forecast_df.dropna(inplace=True)\n",
    "\n",
    "print(forecast_df.empty)\n",
    "\n",
    "forecast_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert the bike and weather data into Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No bike data available for today\n"
     ]
    }
   ],
   "source": [
    "if df_bike_today.empty:\n",
    "    print(\"No bike data available for today\")\n",
    "else:\n",
    "    bike_fg.insert(df_bike_today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 240/240 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_data_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1207494/jobs/named/weather_data_1_offline_fg_materialization/executions\n",
      "2025-01-08 17:07:25,548 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-01-08 17:07:28,719 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-01-08 17:09:13,659 INFO: Waiting for execution to finish. Current state: SUCCEEDING. Final status: UNDEFINED\n",
      "2025-01-08 17:09:16,839 INFO: Waiting for execution to finish. Current state: FINISHED. Final status: SUCCEEDED\n",
      "2025-01-08 17:09:17,228 INFO: Waiting for log aggregation to finish.\n",
      "2025-01-08 17:09:17,229 INFO: Execution finished successfully.\n"
     ]
    }
   ],
   "source": [
    "if forecast_df.empty:\n",
    "    print(\"No weather forecast available for today\")\n",
    "else:\n",
    "    weather_fg.insert(forecast_df, write_options={\"wait_for_job\": True})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SML_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
